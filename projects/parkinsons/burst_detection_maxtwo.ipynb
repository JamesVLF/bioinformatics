{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44998f3a",
   "metadata": {},
   "source": [
    "## Initial Processing of MaxTwo Kolf and H9 syn-GFP Human Midbrain Organoids for Parkinson's Induction Experiments Round Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1496f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set up imports and paths ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from burst_analysis.loading import SpikeDataLoader\n",
    "from burst_analysis.detection import BurstDetection\n",
    "from burst_analysis.plotting import BurstDetectionPlots\n",
    "from burst_analysis.loading import SpikeDataLoader\n",
    "from projects.parkinsons.coordinator import OrchestratorPDx2\n",
    "\n",
    "\n",
    "# Set the project root so Python can find analysis_libs and others\n",
    "project_root = Path(\"~/bioinformatics\").expanduser().resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Define the data directory\n",
    "data_path = project_root / \"data/extracted/maxtwo_H9SynGFP\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab99fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to dataset: d0s2_Control\n",
      "Set d0s2_Control as default dataset.\n",
      "Datasets loaded: ['d0s2_Control', 'd0s6_Treated', 'd6s2_Control', 'd6s6_Treated']\n"
     ]
    }
   ],
   "source": [
    "# Load \n",
    "\n",
    "data_path = Path(\"~/bioinformatics/data/extracted/maxtwo_H9SynGFP\").expanduser()\n",
    "\n",
    "orc = OrchestratorPDx2()\n",
    "print(\"Datasets loaded:\", orc.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ccec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to dataset: M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "Set 'M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr' as default dataset (first available).\n",
      "Datasets loaded: ['M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs2_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs4_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs4_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs4_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs2_H9SynGFP_D47_CONTROL_T2_D4', 'M08754bs1_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs2_H9SynGFP_D48_175µM_T2_D5', 'M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs5_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs2_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs6_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs2_H9SynGFP_D47_175µM_T2_D4', 'M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr', 'M06943bs4_H9SynGFP_D42_175µM_T1_3hrs', 'M06943bs5_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs6_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs3_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs1_H9SynGFP_D47_175µM_T2_D4', 'M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr', 'M06943bs3_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs5_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs1_H9SynGFP_D48_175µM_T2_D5', 'M06943bs3_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs1_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs5_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs3_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs3_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs5_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs5_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs5_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs1_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs3_H9SynGFP_D42_175µM_T1_3hrs', 'M06943bs4_H9SynGFP_D48_175µM_T2_D5', 'M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs2_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs1_H9SynGFP_D49_CONTROL_T2_D6', 'M08754bs2_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs4_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs2_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs2_H9SynGFP_D46_175µM_T2_72hr', 'M08754bs6_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs4_H9SynGFP_D47_175µM_T2_D4', 'M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs4_H9SynGFP_D46_175µM_T2_72hr', 'M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr', 'M06943bs6_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr', 'M08754bs2_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs6_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs4_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs5_H9SynGFP_D48_175µM_T2_D5', 'M08754bs6_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs1_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs5_H9SynGFP_D47_175µM_T2_D4', 'M06943bs6_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs4_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs5_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs3_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs6_H9SynGFP_D47_175µM_T2_D4', 'M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr', 'M06943bs1_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs6_H9SynGFP_D43_175µM_T2_3hr', 'M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs2_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs1_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs6_H9SynGFP_D48_175µM_T2_D5', 'M08754bs4_H9SynGFP_D49_CONTROL_T2_D6', 'M08754bs5_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs1_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr', 'M08754bs3_H9SynGFP_D48_CONTROL_T2_D5', 'M08754bs1_H9SynGFP_D47_CONTROL_T2_D4', 'M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs3_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs1_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs3_H9SynGFP_D48_175µM_T2_D5', 'M06943bs2_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr', 'M06943bs4_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M06943bs6_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr', 'M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs5_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs3_H9SynGFP_D47_175µM_T2_D4', 'M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M06943bs6_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs3_H9SynGFP_D49_CONTROL_T2_D6']\n"
     ]
    }
   ],
   "source": [
    "from projects.parkinsons.coordinator import OrchestratorPDx2\n",
    "from pathlib import Path\n",
    "\n",
    "folder = Path(\"/Users/main_mac/bioinformatics/data/extracted/maxtwo_H9SynGFP\")\n",
    "spike_paths = {f.stem: str(f) for f in folder.glob(\"*.npz\")}\n",
    "\n",
    "orc = OrchestratorPDx2(spike_paths=spike_paths)\n",
    "print(\"Datasets loaded:\", orc.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b5bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to dataset: d0s2_Control\n",
      "Set d0s2_Control as default dataset.\n",
      "Orchestrator initialized.\n",
      "Available dataset keys: ['d0s2_Control', 'd0s6_Treated', 'd6s2_Control', 'd6s6_Treated']\n"
     ]
    }
   ],
   "source": [
    "from projects.parkinsons.coordinator import OrchestratorPDx2\n",
    "\n",
    "orc = OrchestratorPDx2()\n",
    "print(\"Orchestrator initialized.\")\n",
    "print(\"Available dataset keys:\", orc.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a438edc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs2_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs4_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs4_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs4_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs2_H9SynGFP_D47_CONTROL_T2_D4', 'M08754bs1_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs2_H9SynGFP_D48_175µM_T2_D5', 'M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs5_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs2_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs6_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs2_H9SynGFP_D47_175µM_T2_D4', 'M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr', 'M06943bs4_H9SynGFP_D42_175µM_T1_3hrs', 'M06943bs5_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs6_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs3_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs1_H9SynGFP_D47_175µM_T2_D4', 'M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr', 'M06943bs3_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs5_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs1_H9SynGFP_D48_175µM_T2_D5', 'M06943bs3_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs1_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs5_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs3_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs3_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs5_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs5_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs5_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs1_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs3_H9SynGFP_D42_175µM_T1_3hrs', 'M06943bs4_H9SynGFP_D48_175µM_T2_D5', 'M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs2_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs1_H9SynGFP_D49_CONTROL_T2_D6', 'M08754bs2_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs4_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs2_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs2_H9SynGFP_D46_175µM_T2_72hr', 'M08754bs6_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs4_H9SynGFP_D47_175µM_T2_D4', 'M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs4_H9SynGFP_D46_175µM_T2_72hr', 'M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr', 'M06943bs6_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr', 'M08754bs2_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs6_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs4_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs5_H9SynGFP_D48_175µM_T2_D5', 'M08754bs6_H9SynGFP_D47_CONTROL_T2_D4', 'M06943bs1_H9SynGFP_D43_175µM_T2_3hr', 'M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs5_H9SynGFP_D47_175µM_T2_D4', 'M06943bs6_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr', 'M08754bs4_H9SynGFP_D42_CONTROL_T1_3hrs', 'M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr', 'M06943bs5_H9SynGFP_D44_175µM_T2_24hr', 'M06943bs3_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs6_H9SynGFP_D47_175µM_T2_D4', 'M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr', 'M06943bs1_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs6_H9SynGFP_D43_175µM_T2_3hr', 'M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs2_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr', 'M06943bs1_H9SynGFP_D45_175µM_T2_48hr', 'M06943bs6_H9SynGFP_D48_175µM_T2_D5', 'M08754bs4_H9SynGFP_D49_CONTROL_T2_D6', 'M08754bs5_H9SynGFP_D48_CONTROL_T2_D5', 'M06943bs1_H9SynGFP_D42_175µM_T1_3hrs', 'M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr', 'M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr', 'M08754bs3_H9SynGFP_D48_CONTROL_T2_D5', 'M08754bs1_H9SynGFP_D47_CONTROL_T2_D4', 'M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr', 'M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr', 'M08754bs3_H9SynGFP_D42_CONTROL_T1_3hrs', 'M06943bs1_H9SynGFP_D43_175µM_T1_24hr', 'M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr', 'M06943bs3_H9SynGFP_D48_175µM_T2_D5', 'M06943bs2_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr', 'M06943bs4_H9SynGFP_D44_175µM_T2_24hr', 'M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M06943bs6_H9SynGFP_D46_175µM_T2_72hr', 'M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr', 'M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M08754bs5_H9SynGFP_D49_CONTROL_T2_D6', 'M06943bs3_H9SynGFP_D47_175µM_T2_D4', 'M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr', 'M06943bs6_H9SynGFP_D45_175µM_T2_48hr', 'M08754bs3_H9SynGFP_D49_CONTROL_T2_D6']\n"
     ]
    }
   ],
   "source": [
    "datasets = list(orc.spike_data.keys())\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cdd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spike data for M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr with 124 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D43_175µM_T1_24hr with 200 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr with 120 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D47_CONTROL_T2_D4 with 194 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D43_175µM_T2_3hr with 122 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D43_175µM_T1_24hr with 200 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr with 99 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D47_CONTROL_T2_D4 with 298 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D42_CONTROL_T1_3hrs with 338 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D48_175µM_T2_D5 with 68 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr with 341 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D42_CONTROL_T1_3hrs with 112 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D42_175µM_T1_3hrs with 187 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D48_CONTROL_T2_D5 with 99 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D47_175µM_T2_D4 with 95 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr with 307 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D42_175µM_T1_3hrs with 154 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D45_175µM_T2_48hr with 71 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D49_CONTROL_T2_D6 with 104 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D43_175µM_T2_3hr with 123 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D47_175µM_T2_D4 with 53 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr with 159 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D45_175µM_T2_48hr with 85 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D46_175µM_T2_72hr with 50 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D48_175µM_T2_D5 with 44 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D46_175µM_T2_72hr with 75 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr with 191 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D44_175µM_T2_24hr with 70 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D43_175µM_T1_24hr with 97 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D47_CONTROL_T2_D4 with 197 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D43_175µM_T1_24hr with 272 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr with 151 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D47_CONTROL_T2_D4 with 107 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D43_175µM_T2_3hr with 62 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D42_175µM_T1_3hrs with 76 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr with 334 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D48_CONTROL_T2_D5 with 320 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr with 305 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D42_175µM_T1_3hrs with 249 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D48_175µM_T2_D5 with 61 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr with 110 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D45_175µM_T2_48hr with 123 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr with 215 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr with 111 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D49_CONTROL_T2_D6 with 318 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D42_CONTROL_T1_3hrs with 372 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr with 120 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D45_175µM_T2_48hr with 117 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D43_175µM_T2_3hr with 141 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D46_175µM_T2_72hr with 89 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D42_CONTROL_T1_3hrs with 133 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr with 353 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D47_175µM_T2_D4 with 83 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr with 161 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D46_175µM_T2_72hr with 96 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr with 375 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D44_175µM_T2_24hr with 156 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr with 214 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D48_CONTROL_T2_D5 with 297 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D42_175µM_T1_3hrs with 213 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D48_CONTROL_T2_D5 with 169 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D48_175µM_T2_D5 with 59 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D47_CONTROL_T2_D4 with 104 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D43_175µM_T2_3hr with 110 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr with 250 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D47_175µM_T2_D4 with 58 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D43_175µM_T1_24hr with 256 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr with 269 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D42_CONTROL_T1_3hrs with 264 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr with 213 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D44_175µM_T2_24hr with 60 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D44_175µM_T2_24hr with 117 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr with 357 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D47_175µM_T2_D4 with 129 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr with 157 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D46_175µM_T2_72hr with 50 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D43_175µM_T2_3hr with 156 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr with 231 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr with 378 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D49_CONTROL_T2_D6 with 286 units.\n",
      "Loaded spike data for M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr with 130 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D45_175µM_T2_48hr with 67 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D48_175µM_T2_D5 with 126 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D49_CONTROL_T2_D6 with 162 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D48_CONTROL_T2_D5 with 97 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D42_175µM_T1_3hrs with 254 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr with 171 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr with 143 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr with 408 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D48_CONTROL_T2_D5 with 143 units.\n",
      "Loaded spike data for M08754bs1_H9SynGFP_D47_CONTROL_T2_D4 with 324 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr with 409 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr with 239 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D42_CONTROL_T1_3hrs with 173 units.\n",
      "Loaded spike data for M06943bs1_H9SynGFP_D43_175µM_T1_24hr with 218 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr with 290 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D48_175µM_T2_D5 with 50 units.\n",
      "Loaded spike data for M06943bs2_H9SynGFP_D44_175µM_T2_24hr with 107 units.\n",
      "Loaded spike data for M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr with 137 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr with 196 units.\n",
      "Loaded spike data for M06943bs4_H9SynGFP_D44_175µM_T2_24hr with 107 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr with 127 units.\n",
      "Loaded spike data for M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr with 285 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D46_175µM_T2_72hr with 142 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr with 295 units.\n",
      "Loaded spike data for M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr with 338 units.\n",
      "Loaded spike data for M08754bs5_H9SynGFP_D49_CONTROL_T2_D6 with 99 units.\n",
      "Loaded spike data for M06943bs3_H9SynGFP_D47_175µM_T2_D4 with 63 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr with 178 units.\n",
      "Loaded spike data for M06943bs6_H9SynGFP_D45_175µM_T2_48hr with 183 units.\n",
      "Loaded spike data for M08754bs3_H9SynGFP_D49_CONTROL_T2_D6 with 156 units.\n",
      "Switched to dataset: M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "Active dataset: M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\n"
     ]
    }
   ],
   "source": [
    "# load with alignment so metadata['cluster_ids'] is populated\n",
    "orc.loader.spike_data = orc.loader.load_and_align_spike_data(orc.loader.spike_paths)\n",
    "\n",
    "# (Optional) reset sd_main to something valid\n",
    "first_key = next(iter(orc.loader.spike_data))\n",
    "orc.loader.set_dataset(first_key)\n",
    "print(\"Active dataset:\", first_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7167289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr — 124 aligned units\n",
      "  Neuron 0: cluster_id = 3\n",
      "    Spike count: 2168\n",
      "    First 5 spikes: [np.float64(1.9067), np.float64(1.9131), np.float64(1.9228), np.float64(2.0015), np.float64(2.0224)]\n",
      "    Metadata keys: ['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates']\n",
      "    Cluster ID:     3\n",
      "----------------------------------------\n",
      "  Neuron 1: cluster_id = 5\n",
      "    Spike count: 188\n",
      "    First 5 spikes: [np.float64(447.3107), np.float64(447.3713), np.float64(447.5749), np.float64(448.2351), np.float64(449.267)]\n",
      "    Metadata keys: ['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates']\n",
      "    Cluster ID:     5\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check that the keys in the .npz files were properly aligned to the same neuron through a common cluster id\n",
    "\n",
    "file_id = \"M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\"\n",
    "spike_data = orc.spike_data[file_id]\n",
    "cluster_ids = spike_data.metadata.get(\"cluster_ids\", [])\n",
    "\n",
    "print(f\"\\n{file_id} — {len(cluster_ids)} aligned units\")\n",
    "\n",
    "for i, cluster_id in enumerate(cluster_ids[:2]):  # only show first 2\n",
    "    spikes = spike_data.train[i]\n",
    "\n",
    "    # Load the original file to access neuron metadata\n",
    "    original_data = np.load(orc.loader.spike_paths[file_id], allow_pickle=True)\n",
    "    neuron_data = original_data[\"neuron_data\"].item()\n",
    "\n",
    "    # Find metadata entry that matches this cluster_id\n",
    "    meta = next(\n",
    "        (meta for meta in neuron_data.values() if meta.get(\"cluster_id\") == cluster_id),\n",
    "        {}\n",
    "    )\n",
    "\n",
    "    print(f\"  Neuron {i}: cluster_id = {cluster_id}\")\n",
    "    print(f\"    Spike count: {len(spikes)}\")\n",
    "    print(f\"    First 5 spikes: {list(spikes[:5])}\")\n",
    "    print(f\"    Metadata keys: {list(meta.keys()) if meta else 'N/A'}\")\n",
    "    print(f\"    Cluster ID:     {meta.get('cluster_id', 'N/A')}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86000e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 124\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 200\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 120\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 194\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 122\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 200\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 99\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 298\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 338\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 68\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 341\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 112\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 187\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 99\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 95\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 307\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 154\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 71\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 104\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 123\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 53\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 159\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 85\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 50\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 44\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 75\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 191\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 70\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 97\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 197\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 272\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 151\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 107\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 62\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 76\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 334\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 320\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 305\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 249\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 61\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 110\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 123\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 215\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 111\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 318\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 372\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 120\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 117\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 141\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 89\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 133\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 353\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 83\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 161\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 96\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 375\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 156\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 214\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 297\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 213\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 169\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 59\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 104\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 110\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 250\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 58\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 256\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 269\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 264\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 213\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 60\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 117\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 357\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 129\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 157\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 50\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 156\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 231\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 378\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 286\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 130\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 67\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 126\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 162\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 97\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 254\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 171\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 143\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 408\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 143\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 324\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 409\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 239\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 173\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 218\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 290\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D48_175µM_T2_D5\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 50\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 107\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 137\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 196\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 107\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 127\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 285\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 142\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 295\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 338\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 99\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D47_175µM_T2_D4\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 63\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 178\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 183\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Metadata keys: ['cluster_ids', 'fs', 'config']\n",
      "  Sampling rate (fs): 10000.0\n",
      "  Neuron count: 156\n",
      "  Example neuron attribute keys:\n",
      "    dict_keys(['cluster_id', 'channel', 'position', 'template', 'amplitudes', 'waveforms', 'neighbor_channels', 'neighbor_positions', 'neighbor_templates'])\n"
     ]
    }
   ],
   "source": [
    "# .npz files are now a SpikeData object--iterate over the items in the spike_data dictionary\n",
    "\n",
    "for key, sd in orc.loader.spike_data.items():\n",
    "    print(f\"\\nDataset: {key}\")\n",
    "\n",
    "    # Metadata keys\n",
    "    print(\"  Metadata keys:\", list(sd.metadata.keys()))\n",
    "    print(\"  Sampling rate (fs):\", sd.metadata.get(\"fs\"))\n",
    "\n",
    "    # NeuronAttributes summary\n",
    "    if hasattr(sd, \"neuron_attributes\"):\n",
    "        print(\"  Neuron count:\", len(sd.neuron_attributes or []))\n",
    "        if sd.neuron_attributes:\n",
    "            print(\"  Example neuron attribute keys:\")\n",
    "            print(\"   \", vars(sd.neuron_attributes[0]).keys())\n",
    "    else:\n",
    "        print(\"  No neuron_attributes found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eadb7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 124\n",
      "  Neuron attribute count: 124\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2168 spikes, first 5 times: [1.9067 1.9131 1.9228 2.0015 2.0224]\n",
      "    Neuron 1: 188 spikes, first 5 times: [447.3107 447.3713 447.5749 448.2351 449.267 ]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 200\n",
      "  Neuron attribute count: 200\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3389 spikes, first 5 times: [0.5626 0.649  0.6712 0.6995 0.7378]\n",
      "    Neuron 1: 2342 spikes, first 5 times: [3.2857 3.3118 3.3326 3.3492 3.3678]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Spike train count: 120\n",
      "  Neuron attribute count: 120\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3556 spikes, first 5 times: [0.7403 0.7498 0.764  0.8077 0.8553]\n",
      "    Neuron 1: 266 spikes, first 5 times: [ 1.7305  4.5658  7.2585 10.1115 13.0826]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 194\n",
      "  Neuron attribute count: 194\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1858 spikes, first 5 times: [0.1021 0.3112 2.6478 2.6605 2.6723]\n",
      "    Neuron 1: 185 spikes, first 5 times: [ 1.5148 27.03   31.9656 41.9995 47.6572]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 122\n",
      "  Neuron attribute count: 122\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1521 spikes, first 5 times: [0.0939 2.7825 2.9645 3.255  3.6028]\n",
      "    Neuron 1: 2186 spikes, first 5 times: [8.5831 8.6287 8.6929 8.758  8.8014]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 200\n",
      "  Neuron attribute count: 200\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2067 spikes, first 5 times: [0.164  0.3832 0.6161 0.7451 1.3783]\n",
      "    Neuron 1: 1916 spikes, first 5 times: [0.0733 0.3008 0.5303 0.6812 1.3327]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 99\n",
      "  Neuron attribute count: 99\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 905 spikes, first 5 times: [3.4385 3.4485 5.7572 5.7677 7.8551]\n",
      "    Neuron 1: 342 spikes, first 5 times: [ 3.6545  6.6261 11.2241 15.2348 18.3632]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 298\n",
      "  Neuron attribute count: 298\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2520 spikes, first 5 times: [0.5825 0.5933 0.7198 0.7607 2.5838]\n",
      "    Neuron 1: 1275 spikes, first 5 times: [0.5545 0.5709 0.5882 0.6086 0.6285]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 338\n",
      "  Neuron attribute count: 338\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1556 spikes, first 5 times: [0.5607 0.6052 1.0955 1.3838 1.4157]\n",
      "    Neuron 1: 823 spikes, first 5 times: [ 4.4323  4.4393 15.8767 17.1354 17.5649]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 68\n",
      "  Neuron attribute count: 68\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1152 spikes, first 5 times: [3.0713 3.0837 3.0946 3.142  3.1617]\n",
      "    Neuron 1: 1044 spikes, first 5 times: [0.1713 0.1864 0.2027 0.2467 0.3194]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 341\n",
      "  Neuron attribute count: 341\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 209 spikes, first 5 times: [ 0.7041  5.7263 11.055  16.4455 22.1851]\n",
      "    Neuron 1: 1024 spikes, first 5 times: [0.441  2.0104 2.0221 2.9977 3.9164]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 112\n",
      "  Neuron attribute count: 112\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 335 spikes, first 5 times: [ 0.5503  5.1859  7.3848 10.0293 12.1424]\n",
      "    Neuron 1: 170 spikes, first 5 times: [ 5.7931 12.1935 15.9635 19.1258 22.6586]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 187\n",
      "  Neuron attribute count: 187\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 891 spikes, first 5 times: [14.3622 14.3975 14.4228 14.4428 14.4564]\n",
      "    Neuron 1: 2315 spikes, first 5 times: [0.3719 1.4718 1.4952 1.5141 1.5358]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 99\n",
      "  Neuron attribute count: 99\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2955 spikes, first 5 times: [0.118  0.1309 0.789  0.8006 1.4184]\n",
      "    Neuron 1: 2205 spikes, first 5 times: [1.5359 1.7874 1.9099 1.9719 2.0007]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 95\n",
      "  Neuron attribute count: 95\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1688 spikes, first 5 times: [3.2471 3.2617 3.3136 3.3466 3.3891]\n",
      "    Neuron 1: 1855 spikes, first 5 times: [0.0759 0.2017 0.2286 0.3097 2.2661]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 307\n",
      "  Neuron attribute count: 307\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 405 spikes, first 5 times: [ 6.9626  7.1137 10.7411 12.867  14.4902]\n",
      "    Neuron 1: 460 spikes, first 5 times: [0.0857 0.4787 0.8916 2.0668 4.4439]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 154\n",
      "  Neuron attribute count: 154\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1625 spikes, first 5 times: [30.5445 34.0578 47.0333 52.122  52.6195]\n",
      "    Neuron 1: 258 spikes, first 5 times: [ 3.7529 30.5444 34.058  47.0334 47.4374]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 71\n",
      "  Neuron attribute count: 71\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 971 spikes, first 5 times: [485.5461 486.0527 486.5132 490.2099 506.3201]\n",
      "    Neuron 1: 2456 spikes, first 5 times: [1.2255 1.2446 1.264  1.2892 1.3089]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 104\n",
      "  Neuron attribute count: 104\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 427 spikes, first 5 times: [ 1.4404  8.0945 17.3733 17.6959 20.1221]\n",
      "    Neuron 1: 431 spikes, first 5 times: [ 6.9666  9.2987  9.6749 11.324  12.0545]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 123\n",
      "  Neuron attribute count: 123\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2551 spikes, first 5 times: [0.0358 0.0812 0.1254 0.1626 0.1971]\n",
      "    Neuron 1: 917 spikes, first 5 times: [0.8631 1.7059 1.935  2.3747 2.6502]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 53\n",
      "  Neuron attribute count: 53\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 4417 spikes, first 5 times: [6.6845 6.6941 6.7016 6.7085 6.7152]\n",
      "    Neuron 1: 1645 spikes, first 5 times: [ 2.5908 11.1163 12.7814 12.854  12.8723]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Spike train count: 159\n",
      "  Neuron attribute count: 159\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 338 spikes, first 5 times: [19.7007 20.8719 20.9114 21.2123 21.3043]\n",
      "    Neuron 1: 430 spikes, first 5 times: [  1.2649 303.881  393.474  394.0339 395.0485]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 85\n",
      "  Neuron attribute count: 85\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1019 spikes, first 5 times: [0.0477 0.078  0.5643 0.9237 1.8863]\n",
      "    Neuron 1: 1974 spikes, first 5 times: [0.0177 0.5404 0.7853 0.9415 1.5438]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 50\n",
      "  Neuron attribute count: 50\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1640 spikes, first 5 times: [0.7017 0.7551 0.8184 3.3421 3.4032]\n",
      "    Neuron 1: 168 spikes, first 5 times: [ 3.3722  6.2467 15.7831 18.659  23.2163]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 44\n",
      "  Neuron attribute count: 44\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 487 spikes, first 5 times: [ 2.4575  2.4759  7.3058  7.325  11.8644]\n",
      "    Neuron 1: 4418 spikes, first 5 times: [0.5342 0.5391 0.5666 0.5749 0.5951]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 75\n",
      "  Neuron attribute count: 75\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2100 spikes, first 5 times: [2.2543 2.2785 2.2977 2.3208 4.3622]\n",
      "    Neuron 1: 2506 spikes, first 5 times: [0.102  0.2212 1.8499 1.9629 1.9864]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 191\n",
      "  Neuron attribute count: 191\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 353 spikes, first 5 times: [ 0.1324  1.4658 11.6981 14.9633 15.5493]\n",
      "    Neuron 1: 369 spikes, first 5 times: [ 0.0725  3.1251  7.9303 10.627  15.0003]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 70\n",
      "  Neuron attribute count: 70\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 349 spikes, first 5 times: [ 0.2403  3.9989  7.4839  8.5696 10.7147]\n",
      "    Neuron 1: 2968 spikes, first 5 times: [4.9845 5.0276 5.0705 5.116  5.1619]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 97\n",
      "  Neuron attribute count: 97\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1506 spikes, first 5 times: [1.5247 1.6284 1.7325 1.9361 4.6207]\n",
      "    Neuron 1: 3175 spikes, first 5 times: [0.3133 0.397  0.4818 0.5798 0.6162]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 197\n",
      "  Neuron attribute count: 197\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1117 spikes, first 5 times: [1.572  1.5835 2.8964 2.9086 2.9328]\n",
      "    Neuron 1: 1088 spikes, first 5 times: [0.0288 3.2325 4.727  6.1199 6.2119]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 272\n",
      "  Neuron attribute count: 272\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 459 spikes, first 5 times: [ 7.8479 14.2637 15.8676 23.9885 26.0556]\n",
      "    Neuron 1: 396 spikes, first 5 times: [65.893  65.9144 65.9364 65.958  65.98  ]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Spike train count: 151\n",
      "  Neuron attribute count: 151\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1935 spikes, first 5 times: [1.0907 5.5164 5.7224 5.9337 6.3675]\n",
      "    Neuron 1: 2389 spikes, first 5 times: [6.7882 6.8258 6.8613 6.8944 6.9212]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 107\n",
      "  Neuron attribute count: 107\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 767 spikes, first 5 times: [ 30.0343 295.749  295.7992 295.8111 295.825 ]\n",
      "    Neuron 1: 716 spikes, first 5 times: [0.6882 1.0319 1.0611 4.0558 6.0453]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 62\n",
      "  Neuron attribute count: 62\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1102 spikes, first 5 times: [ 1.043   9.4238  9.6686 10.336  14.0651]\n",
      "    Neuron 1: 1980 spikes, first 5 times: [ 4.9396  8.6045 11.8042 12.1343 12.291 ]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 76\n",
      "  Neuron attribute count: 76\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 820 spikes, first 5 times: [0.8384 0.8755 0.9369 0.9842 1.0694]\n",
      "    Neuron 1: 2540 spikes, first 5 times: [1.7017 1.7288 1.7491 2.8645 4.811 ]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Spike train count: 334\n",
      "  Neuron attribute count: 334\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1144 spikes, first 5 times: [0.663  0.6852 0.7147 0.738  4.6192]\n",
      "    Neuron 1: 588 spikes, first 5 times: [ 3.7597  5.8346  5.846  10.9214 10.9324]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 320\n",
      "  Neuron attribute count: 320\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 392 spikes, first 5 times: [ 1.881   4.3066  6.561   8.8796 10.8174]\n",
      "    Neuron 1: 177 spikes, first 5 times: [ 3.314  10.3641 13.6762 16.5851 22.1631]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 305\n",
      "  Neuron attribute count: 305\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 264 spikes, first 5 times: [ 2.9503  6.1878 10.1162 13.4823 19.1203]\n",
      "    Neuron 1: 1989 spikes, first 5 times: [0.1168 0.165  0.2016 0.2475 0.2956]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 249\n",
      "  Neuron attribute count: 249\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1749 spikes, first 5 times: [0.3596 1.1052 2.4935 3.3301 5.7126]\n",
      "    Neuron 1: 437 spikes, first 5 times: [0.9218 1.3004 1.467  1.6228 2.5394]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 61\n",
      "  Neuron attribute count: 61\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 4894 spikes, first 5 times: [0.6269 0.6329 0.6413 0.6589 0.6725]\n",
      "    Neuron 1: 830 spikes, first 5 times: [2.2252 2.2446 2.3125 2.4972 8.6709]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 110\n",
      "  Neuron attribute count: 110\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1342 spikes, first 5 times: [2.2124 2.44   2.6257 2.847  6.1936]\n",
      "    Neuron 1: 2800 spikes, first 5 times: [4.0982 4.1166 4.1355 4.1598 4.1772]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 123\n",
      "  Neuron attribute count: 123\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1389 spikes, first 5 times: [0.637  0.656  0.8778 0.9493 3.6693]\n",
      "    Neuron 1: 1511 spikes, first 5 times: [12.7606 12.7747 12.8035 12.8413 12.8621]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 215\n",
      "  Neuron attribute count: 215\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1125 spikes, first 5 times: [1.7432 1.7793 1.8146 1.8652 1.9147]\n",
      "    Neuron 1: 4614 spikes, first 5 times: [0.039  0.0585 0.077  0.0968 0.125 ]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Spike train count: 111\n",
      "  Neuron attribute count: 111\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 534 spikes, first 5 times: [1.4251 3.2355 4.3285 6.2455 6.8007]\n",
      "    Neuron 1: 2715 spikes, first 5 times: [1.6745 1.6881 1.7424 1.7844 1.8215]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 318\n",
      "  Neuron attribute count: 318\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 5971 spikes, first 5 times: [0.0747 0.1406 1.5449 1.5586 1.5927]\n",
      "    Neuron 1: 2211 spikes, first 5 times: [0.0508 0.6439 0.7113 1.1135 1.3136]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 372\n",
      "  Neuron attribute count: 372\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3827 spikes, first 5 times: [0.3476 0.3862 0.4158 0.4575 0.561 ]\n",
      "    Neuron 1: 471 spikes, first 5 times: [ 3.0627  6.6309  7.8399 12.1213 15.5158]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 120\n",
      "  Neuron attribute count: 120\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1615 spikes, first 5 times: [0.0933 0.3388 0.5459 0.7652 1.6451]\n",
      "    Neuron 1: 7056 spikes, first 5 times: [1.5808 1.5883 1.5988 1.6355 1.6551]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 117\n",
      "  Neuron attribute count: 117\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 112 spikes, first 5 times: [ 79.7537 101.2898 135.8291 141.9028 227.5301]\n",
      "    Neuron 1: 3593 spikes, first 5 times: [0.7418 0.7655 0.7935 0.8345 0.8736]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 141\n",
      "  Neuron attribute count: 141\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 630 spikes, first 5 times: [1.7725 1.8244 1.8448 1.8866 1.9319]\n",
      "    Neuron 1: 5678 spikes, first 5 times: [0.0195 0.044  0.0753 0.1051 0.1623]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 89\n",
      "  Neuron attribute count: 89\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1015 spikes, first 5 times: [181.7932 181.8084 181.847  181.8827 181.9429]\n",
      "    Neuron 1: 3481 spikes, first 5 times: [0.4    0.4504 0.4867 0.5202 0.5683]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 133\n",
      "  Neuron attribute count: 133\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2830 spikes, first 5 times: [0.0259 0.061  0.1726 0.2018 0.2368]\n",
      "    Neuron 1: 1644 spikes, first 5 times: [0.0342 0.067  0.1099 0.1778 0.2088]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 353\n",
      "  Neuron attribute count: 353\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 651 spikes, first 5 times: [13.189  13.2505 14.732  14.7589 14.7708]\n",
      "    Neuron 1: 164 spikes, first 5 times: [512.4417 512.4509 512.4614 512.4718 512.4839]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 83\n",
      "  Neuron attribute count: 83\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 597 spikes, first 5 times: [1.4221 1.8547 4.7093 4.8095 7.7868]\n",
      "    Neuron 1: 2150 spikes, first 5 times: [0.1379 0.1903 0.2169 0.2541 3.3813]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 161\n",
      "  Neuron attribute count: 161\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1258 spikes, first 5 times: [1.3506 1.3743 1.3987 1.4624 4.0748]\n",
      "    Neuron 1: 2213 spikes, first 5 times: [5.8505 6.2167 6.6486 6.8475 6.9506]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 96\n",
      "  Neuron attribute count: 96\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1796 spikes, first 5 times: [20.8739 20.8791 20.8898 20.9077 20.9202]\n",
      "    Neuron 1: 1355 spikes, first 5 times: [0.6969 0.7228 0.7675 3.4291 3.4681]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Spike train count: 375\n",
      "  Neuron attribute count: 375\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 151 spikes, first 5 times: [ 5.1357  9.6312 16.6802 22.1898 26.7362]\n",
      "    Neuron 1: 229 spikes, first 5 times: [ 0.0574  3.152   4.9345 10.0088 12.0948]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 156\n",
      "  Neuron attribute count: 156\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 4721 spikes, first 5 times: [4.4763 4.5047 4.5275 4.544  4.5602]\n",
      "    Neuron 1: 100 spikes, first 5 times: [ 59.053   62.7589  64.267  101.2645 105.4381]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 214\n",
      "  Neuron attribute count: 214\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 416 spikes, first 5 times: [ 0.4389  3.5514  5.6517  7.8558 10.4081]\n",
      "    Neuron 1: 1918 spikes, first 5 times: [0.8607 0.8833 0.9225 0.9548 0.9878]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 297\n",
      "  Neuron attribute count: 297\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1646 spikes, first 5 times: [0.3105 0.6212 0.6798 0.6932 0.708 ]\n",
      "    Neuron 1: 131 spikes, first 5 times: [ 1.0183  6.4138 19.0904 24.8765 27.098 ]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 213\n",
      "  Neuron attribute count: 213\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 843 spikes, first 5 times: [32.0278 72.5128 72.6252 72.7238 72.8173]\n",
      "    Neuron 1: 93 spikes, first 5 times: [296.9857 297.1067 297.136  297.1977 297.2775]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 169\n",
      "  Neuron attribute count: 169\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 295 spikes, first 5 times: [ 0.8905  4.7458  7.012   9.6427 12.9975]\n",
      "    Neuron 1: 108 spikes, first 5 times: [437.7042 604.6092 633.363  657.5065 672.8522]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 59\n",
      "  Neuron attribute count: 59\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3938 spikes, first 5 times: [2.2467 2.2656 2.2823 2.2979 2.3283]\n",
      "    Neuron 1: 4187 spikes, first 5 times: [0.6701 0.6778 0.6868 0.7185 0.7317]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 104\n",
      "  Neuron attribute count: 104\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 526 spikes, first 5 times: [1.3    2.775  4.1598 5.3058 7.3853]\n",
      "    Neuron 1: 387 spikes, first 5 times: [19.4204 22.3951 26.8726 29.3231 34.2514]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 110\n",
      "  Neuron attribute count: 110\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3044 spikes, first 5 times: [0.0385 0.3555 0.3598 0.4742 0.573 ]\n",
      "    Neuron 1: 1470 spikes, first 5 times: [0.4996 0.5713 0.6085 0.6736 0.705 ]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 250\n",
      "  Neuron attribute count: 250\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 130 spikes, first 5 times: [360.9875 361.0041 361.0631 361.1303 361.1943]\n",
      "    Neuron 1: 1352 spikes, first 5 times: [ 5.5127  6.433   6.7916 12.7292 13.0649]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 58\n",
      "  Neuron attribute count: 58\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 145 spikes, first 5 times: [ 3.3601  8.2826 12.27   12.4721 16.4195]\n",
      "    Neuron 1: 765 spikes, first 5 times: [0.523  0.5496 0.619  3.9412 3.9594]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 256\n",
      "  Neuron attribute count: 256\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1656 spikes, first 5 times: [0.1646 0.332  0.4938 0.6835 0.8428]\n",
      "    Neuron 1: 1041 spikes, first 5 times: [1.195  1.2258 1.2605 1.2883 1.3668]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Spike train count: 269\n",
      "  Neuron attribute count: 269\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1091 spikes, first 5 times: [2.4299 5.7085 5.751  5.8199 5.8687]\n",
      "    Neuron 1: 209 spikes, first 5 times: [33.9241 34.9513 55.1145 58.5437 63.172 ]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 264\n",
      "  Neuron attribute count: 264\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 339 spikes, first 5 times: [1.7164 1.7323 1.7434 2.8717 8.5972]\n",
      "    Neuron 1: 3710 spikes, first 5 times: [1.2507 1.2655 1.2807 1.294  1.3091]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 213\n",
      "  Neuron attribute count: 213\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 5697 spikes, first 5 times: [0.091  0.1671 1.2688 1.2802 1.3014]\n",
      "    Neuron 1: 1020 spikes, first 5 times: [1.1768 1.5202 1.5308 1.5383 2.788 ]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 60\n",
      "  Neuron attribute count: 60\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1375 spikes, first 5 times: [0.0177 0.1743 0.4941 1.2331 1.5007]\n",
      "    Neuron 1: 2373 spikes, first 5 times: [1.8139 2.1142 2.3466 2.5371 4.2934]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 117\n",
      "  Neuron attribute count: 117\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 215 spikes, first 5 times: [18.3928 28.683  30.5272 39.6687 50.8114]\n",
      "    Neuron 1: 474 spikes, first 5 times: [ 7.5347  8.1109  8.354  10.7248 11.2325]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 357\n",
      "  Neuron attribute count: 357\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1224 spikes, first 5 times: [4.2909 4.9794 4.9955 8.5476 8.5605]\n",
      "    Neuron 1: 1188 spikes, first 5 times: [8.3097 8.3486 8.4179 8.4833 8.6131]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 129\n",
      "  Neuron attribute count: 129\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 391 spikes, first 5 times: [1.9306 3.5453 6.5764 9.1226 9.131 ]\n",
      "    Neuron 1: 252 spikes, first 5 times: [10.1198 10.1281 18.0386 18.0478 37.9523]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 157\n",
      "  Neuron attribute count: 157\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2014 spikes, first 5 times: [0.0169 0.1371 0.1802 2.1735 2.2764]\n",
      "    Neuron 1: 105 spikes, first 5 times: [390.9212 391.0083 391.028  391.4703 391.6227]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 50\n",
      "  Neuron attribute count: 50\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 800 spikes, first 5 times: [0.0267 0.3039 0.4214 2.3323 3.5338]\n",
      "    Neuron 1: 684 spikes, first 5 times: [15.2503 15.2719 15.3042 15.3658 15.4112]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D43_175µM_T2_3hr\n",
      "  Spike train count: 156\n",
      "  Neuron attribute count: 156\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 848 spikes, first 5 times: [9.5179 9.5718 9.6187 9.6992 9.7398]\n",
      "    Neuron 1: 809 spikes, first 5 times: [1.3846 3.083  3.1354 3.1711 3.2679]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Spike train count: 231\n",
      "  Neuron attribute count: 231\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1144 spikes, first 5 times: [ 18.815   24.8597  96.6992 149.7951 156.6677]\n",
      "    Neuron 1: 1479 spikes, first 5 times: [13.1252 13.1356 13.1588 13.1808 13.2235]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 378\n",
      "  Neuron attribute count: 378\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 490 spikes, first 5 times: [ 4.9322  9.9757 10.0175 10.0353 10.0594]\n",
      "    Neuron 1: 193 spikes, first 5 times: [0.0822 0.7472 2.3806 2.6126 2.9269]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 286\n",
      "  Neuron attribute count: 286\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 355 spikes, first 5 times: [ 1.7264  3.6962 11.1594 11.1676 18.0757]\n",
      "    Neuron 1: 2253 spikes, first 5 times: [0.1555 0.2478 0.2753 0.298  0.3332]\n",
      "\n",
      "Dataset: M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 130\n",
      "  Neuron attribute count: 130\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 704 spikes, first 5 times: [0.8259 0.8545 1.0886 1.1371 1.1778]\n",
      "    Neuron 1: 1392 spikes, first 5 times: [0.4288 0.6089 0.6336 0.7051 0.9089]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 67\n",
      "  Neuron attribute count: 67\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 339 spikes, first 5 times: [23.7006 23.7398 23.7896 23.8502 23.8897]\n",
      "    Neuron 1: 2467 spikes, first 5 times: [0.0146 0.0484 0.0762 0.0973 0.1196]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 126\n",
      "  Neuron attribute count: 126\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 121 spikes, first 5 times: [168.829  197.7723 197.7787 197.8051 197.8207]\n",
      "    Neuron 1: 319 spikes, first 5 times: [ 8.9845 11.2798 14.428  18.3188 21.147 ]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 162\n",
      "  Neuron attribute count: 162\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 4072 spikes, first 5 times: [0.4063 0.5493 0.5574 0.5682 0.5825]\n",
      "    Neuron 1: 243 spikes, first 5 times: [ 0.1204  5.898   9.6187 13.6751 17.7691]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 97\n",
      "  Neuron attribute count: 97\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1721 spikes, first 5 times: [0.1715 0.2131 0.2647 2.5711 2.7054]\n",
      "    Neuron 1: 2915 spikes, first 5 times: [0.2534 0.2755 0.3573 0.3784 0.5176]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D42_175µM_T1_3hrs\n",
      "  Spike train count: 254\n",
      "  Neuron attribute count: 254\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1489 spikes, first 5 times: [2.5137 2.6329 2.8413 2.9123 3.2777]\n",
      "    Neuron 1: 1485 spikes, first 5 times: [1.905  1.9493 1.9791 2.0149 2.0485]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr\n",
      "  Spike train count: 171\n",
      "  Neuron attribute count: 171\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2984 spikes, first 5 times: [0.8512 0.9179 1.2567 1.2713 1.3175]\n",
      "    Neuron 1: 198 spikes, first 5 times: [ 6.9291  8.0247  9.7641 16.4622 23.7093]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 143\n",
      "  Neuron attribute count: 143\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1312 spikes, first 5 times: [1.0922 1.1178 3.9235 3.9391 6.0272]\n",
      "    Neuron 1: 510 spikes, first 5 times: [0.6767 4.0516 6.7906 8.9524 9.5044]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 408\n",
      "  Neuron attribute count: 408\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 919 spikes, first 5 times: [3.1804 3.2201 4.3453 6.2755 6.2934]\n",
      "    Neuron 1: 2343 spikes, first 5 times: [0.9603 2.1459 2.1739 2.2019 2.2202]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D48_CONTROL_T2_D5\n",
      "  Spike train count: 143\n",
      "  Neuron attribute count: 143\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2287 spikes, first 5 times: [1.2658 1.282  1.2932 1.3101 1.342 ]\n",
      "    Neuron 1: 5238 spikes, first 5 times: [0.1143 0.2252 0.278  0.4051 1.3238]\n",
      "\n",
      "Dataset: M08754bs1_H9SynGFP_D47_CONTROL_T2_D4\n",
      "  Spike train count: 324\n",
      "  Neuron attribute count: 324\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1592 spikes, first 5 times: [0.3756 0.6205 1.0729 1.3878 2.5012]\n",
      "    Neuron 1: 1768 spikes, first 5 times: [13.8895 13.96   13.9823 16.4435 16.4712]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr\n",
      "  Spike train count: 409\n",
      "  Neuron attribute count: 409\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1548 spikes, first 5 times: [3.9692 4.0054 4.0491 4.113  4.1613]\n",
      "    Neuron 1: 2323 spikes, first 5 times: [0.4182 0.4928 0.6553 1.8091 1.8701]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr\n",
      "  Spike train count: 239\n",
      "  Neuron attribute count: 239\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 399 spikes, first 5 times: [3.2179 6.0955 8.0815 8.5399 8.8332]\n",
      "    Neuron 1: 2719 spikes, first 5 times: [2.9056 2.9149 2.9508 2.9782 3.0035]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D42_CONTROL_T1_3hrs\n",
      "  Spike train count: 173\n",
      "  Neuron attribute count: 173\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2755 spikes, first 5 times: [2.218  2.2276 2.2373 2.2747 2.3086]\n",
      "    Neuron 1: 2925 spikes, first 5 times: [1.1287 1.1698 1.1883 1.255  1.2753]\n",
      "\n",
      "Dataset: M06943bs1_H9SynGFP_D43_175µM_T1_24hr\n",
      "  Spike train count: 218\n",
      "  Neuron attribute count: 218\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2426 spikes, first 5 times: [0.0332 0.1    0.1338 0.1865 7.2919]\n",
      "    Neuron 1: 657 spikes, first 5 times: [0.8378 2.1169 2.7604 3.0472 3.5005]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr\n",
      "  Spike train count: 290\n",
      "  Neuron attribute count: 290\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 757 spikes, first 5 times: [13.2337 13.2915 13.2975 14.0785 16.8604]\n",
      "    Neuron 1: 3321 spikes, first 5 times: [0.8311 0.8427 0.8611 0.8747 0.8887]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D48_175µM_T2_D5\n",
      "  Spike train count: 50\n",
      "  Neuron attribute count: 50\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 3253 spikes, first 5 times: [0.032  0.0555 3.2005 3.2223 3.2522]\n",
      "    Neuron 1: 302 spikes, first 5 times: [20.8127 33.7481 34.9297 35.4188 40.7135]\n",
      "\n",
      "Dataset: M06943bs2_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 107\n",
      "  Neuron attribute count: 107\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1431 spikes, first 5 times: [0.1598 0.4015 0.7357 0.9405 1.3016]\n",
      "    Neuron 1: 3511 spikes, first 5 times: [7.7044 7.7381 7.7599 7.7789 7.7972]\n",
      "\n",
      "Dataset: M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Spike train count: 137\n",
      "  Neuron attribute count: 137\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 379 spikes, first 5 times: [74.0414 74.094  76.709  78.9554 81.6647]\n",
      "    Neuron 1: 634 spikes, first 5 times: [ 8.1793 10.7191 14.5893 14.6845 14.9746]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr\n",
      "  Spike train count: 196\n",
      "  Neuron attribute count: 196\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 4198 spikes, first 5 times: [28.316  28.3622 28.3985 28.4352 28.4813]\n",
      "    Neuron 1: 605 spikes, first 5 times: [1.3326 1.3502 1.4137 2.9166 4.447 ]\n",
      "\n",
      "Dataset: M06943bs4_H9SynGFP_D44_175µM_T2_24hr\n",
      "  Spike train count: 107\n",
      "  Neuron attribute count: 107\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1832 spikes, first 5 times: [0.6095 1.1891 3.6122 3.7419 4.4957]\n",
      "    Neuron 1: 4694 spikes, first 5 times: [1.6677 1.8099 1.9153 2.0169 2.0952]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Spike train count: 127\n",
      "  Neuron attribute count: 127\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 376 spikes, first 5 times: [ 3.7188  6.871  10.526  14.1793 18.8527]\n",
      "    Neuron 1: 3842 spikes, first 5 times: [0.0094 0.0305 0.9354 0.9481 0.9624]\n",
      "\n",
      "Dataset: M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Spike train count: 285\n",
      "  Neuron attribute count: 285\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1400 spikes, first 5 times: [2.1476 2.3741 2.4022 2.5816 5.3088]\n",
      "    Neuron 1: 331 spikes, first 5 times: [1.7    2.5561 3.0019 3.1163 3.2752]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D46_175µM_T2_72hr\n",
      "  Spike train count: 142\n",
      "  Neuron attribute count: 142\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 563 spikes, first 5 times: [31.0389 31.0487 31.1422 31.1959 32.2   ]\n",
      "    Neuron 1: 247 spikes, first 5 times: [ 0.6358  4.916   4.9454 13.1444 17.9683]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "  Spike train count: 295\n",
      "  Neuron attribute count: 295\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1036 spikes, first 5 times: [0.8983 0.9072 3.0851 3.0954 5.4882]\n",
      "    Neuron 1: 482 spikes, first 5 times: [3.1737 3.1812 3.2405 3.2549 3.2693]\n",
      "\n",
      "Dataset: M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Spike train count: 338\n",
      "  Neuron attribute count: 338\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 435 spikes, first 5 times: [ 2.8272  5.8338  7.741  11.2886 13.9987]\n",
      "    Neuron 1: 583 spikes, first 5 times: [ 2.1747  3.4974  5.8859  8.1719 10.8593]\n",
      "\n",
      "Dataset: M08754bs5_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 99\n",
      "  Neuron attribute count: 99\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1890 spikes, first 5 times: [0.7536 0.8418 2.3644 2.3775 2.433 ]\n",
      "    Neuron 1: 7010 spikes, first 5 times: [1.3071 1.3139 1.3244 1.3435 1.3607]\n",
      "\n",
      "Dataset: M06943bs3_H9SynGFP_D47_175µM_T2_D4\n",
      "  Spike train count: 63\n",
      "  Neuron attribute count: 63\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2209 spikes, first 5 times: [0.0559 0.1967 0.4635 0.6249 0.865 ]\n",
      "    Neuron 1: 846 spikes, first 5 times: [15.137  19.906  19.9341 19.9851 20.1622]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr\n",
      "  Spike train count: 178\n",
      "  Neuron attribute count: 178\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2912 spikes, first 5 times: [0.2599 0.4269 0.4377 0.5286 0.5773]\n",
      "    Neuron 1: 165 spikes, first 5 times: [145.22   298.1373 310.8986 319.5521 329.363 ]\n",
      "\n",
      "Dataset: M06943bs6_H9SynGFP_D45_175µM_T2_48hr\n",
      "  Spike train count: 183\n",
      "  Neuron attribute count: 183\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 2243 spikes, first 5 times: [5.2204 5.2279 5.2538 5.284  5.2997]\n",
      "    Neuron 1: 564 spikes, first 5 times: [0.3764 4.8179 5.6102 8.1014 8.2436]\n",
      "\n",
      "Dataset: M08754bs3_H9SynGFP_D49_CONTROL_T2_D6\n",
      "  Spike train count: 156\n",
      "  Neuron attribute count: 156\n",
      " Spike train and neuron counts match.\n",
      "    Neuron 0: 1412 spikes, first 5 times: [0.4058 0.5894 0.7307 0.9039 0.9275]\n",
      "    Neuron 1: 244 spikes, first 5 times: [309.2076 310.8735 310.8956 311.0766 313.3241]\n"
     ]
    }
   ],
   "source": [
    "# verify that the number of spike trains and the number of units are identical\n",
    "\n",
    "for key, sd in orc.loader.spike_data.items():\n",
    "    print(f\"\\nDataset: {key}\")\n",
    "\n",
    "    train = sd.train\n",
    "    n_attrs = len(sd.neuron_attributes or [])\n",
    "\n",
    "    print(\"  Spike train count:\", len(train))\n",
    "    print(\"  Neuron attribute count:\", n_attrs)\n",
    "\n",
    "    if len(train) != n_attrs:\n",
    "        print(\"  Mismatch between spike trains and neuron attributes!\")\n",
    "    else:\n",
    "        print(\" Spike train and neuron counts match.\")\n",
    "\n",
    "    # peek at a few spike trains\n",
    "    for i in range(min(2, len(train))):\n",
    "        print(f\"    Neuron {i}: {len(train[i])} spikes, first 5 times: {train[i][:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9103d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metrics_df from /Users/main_mac/bioinformatics/projects/parkinsons/metrics.csv (259 rows)\n",
      "Loaded histogram_data (32 datasets)\n",
      "Loaded burst_features_df from /Users/main_mac/bioinformatics/projects/parkinsons/burst_features_full_summary.csv (32 rows)\n",
      "DataFrame audit:\n",
      "  metrics_df: 259\n",
      "  histogram_data: 32\n",
      "  burst_features_df: (32, 23)\n",
      "Saved metrics_df to /Users/main_mac/bioinformatics/projects/parkinsons/metrics.csv (259 rows)\n",
      "Saved histogram_data to /Users/main_mac/bioinformatics/projects/parkinsons/histogram_data.csv (32 datasets)\n",
      "Saved burst_features_df to /Users/main_mac/bioinformatics/projects/parkinsons/burst_features_full_summary.csv (32 rows)\n",
      "Session artifacts saved.\n"
     ]
    }
   ],
   "source": [
    "# import json, csv, and dataframe helper functions\n",
    "\n",
    "from projects.parkinsons.helpers import (_safe_json_load,  \n",
    "                                        _jsonify_list,\n",
    "                                        save_metrics_df, \n",
    "                                        load_metrics_df,\n",
    "                                        save_histogram_data, \n",
    "                                        load_histogram_data,\n",
    "                                        save_burst_features_df, \n",
    "                                        load_burst_features_df,\n",
    "                                        persist_session, \n",
    "                                        reload_session, \n",
    "                                        audit_session_vars,\n",
    "                                        compute_and_save_burst_features\n",
    "                                        )\n",
    "\n",
    "\n",
    "# --- Load prior session artifacts ---\n",
    "session = reload_session(base_dir=\"~/bioinformatics/projects/parkinsons\")\n",
    "metrics_df = session[\"metrics_df\"]\n",
    "histogram_data_df = session[\"histogram_data_df\"]\n",
    "histogram_data  = session[\"histogram_data_list\"]\n",
    "burst_features_df = session[\"burst_features_df\"]\n",
    "audit_session_vars(globals())\n",
    "\n",
    "# --- Persist everything ---\n",
    "persist_session(\n",
    "    metrics_df=metrics_df,\n",
    "    histogram_data=histogram_data,\n",
    "    burst_features_df=burst_features_df,\n",
    "    base_dir=\"~/bioinformatics/projects/parkinsons\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37092fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 259 records from /Users/main_mac/bioinformatics/projects/parkinsons/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "csv_path = Path(\"~/bioinformatics/projects/parkinsons/metrics.csv\").expanduser()\n",
    "\n",
    "def safe_json_load(x):\n",
    "    \"\"\"Safely loads JSON strings, returns original if parsing fails.\"\"\"\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x.startswith(\"[\") and x.endswith(\"]\"):\n",
    "            try:\n",
    "                return json.loads(x)\n",
    "            except json.JSONDecodeError:\n",
    "                return x\n",
    "    return x\n",
    "\n",
    "# Load existing CSV if available\n",
    "if csv_path.exists():\n",
    "    metrics_df = pd.read_csv(csv_path)\n",
    "    for col in metrics_df.columns:\n",
    "        if metrics_df[col].dtype == \"object\":\n",
    "            metrics_df[col] = metrics_df[col].apply(safe_json_load)\n",
    "    print(f\"Loaded {len(metrics_df)} records from {csv_path}\")\n",
    "else:\n",
    "    metrics_df = pd.DataFrame()\n",
    "    print(\"No saved metrics.csv found — starting fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c31c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded histogram_data from histogram_data.parquet (32 rows)\n",
      "Loaded histogram_data from histogram_data.parquet (32 rows)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_histogram_data(path_csv=\"histogram_data.csv\", path_parquet=\"histogram_data.parquet\", as_dict=False):\n",
    "    \"\"\"\n",
    "    Load histogram_data saved by save_histogram_data().\n",
    "    - Returns a list of dicts like:\n",
    "        [{\"Dataset\": ..., \"Group\": ..., \"RelPeaks\": np.array([...])}, ...]\n",
    "    - If as_dict=True, returns {Dataset: np.array([...])}\n",
    "    \"\"\"\n",
    "    # Prefer Parquet if available\n",
    "    if os.path.exists(path_parquet):\n",
    "        df = pd.read_parquet(path_parquet)\n",
    "        source = path_parquet\n",
    "    elif os.path.exists(path_csv):\n",
    "        df = pd.read_csv(path_csv)\n",
    "        source = path_csv\n",
    "    else:\n",
    "        print(\"No histogram_data file found.\")\n",
    "        return {} if as_dict else []\n",
    "\n",
    "    # Parse JSON back to arrays\n",
    "    def parse_relpeaks(x):\n",
    "        try:\n",
    "            if isinstance(x, str):\n",
    "                vals = json.loads(x)\n",
    "            else:\n",
    "                vals = x\n",
    "            return np.array(vals, dtype=float)\n",
    "        except Exception:\n",
    "            return np.array([], dtype=float)\n",
    "\n",
    "    df[\"RelPeaks\"] = df[\"RelPeaks\"].apply(parse_relpeaks)\n",
    "\n",
    "    if as_dict:\n",
    "        out = {row[\"Dataset\"]: row[\"RelPeaks\"] for _, row in df.iterrows()}\n",
    "    else:\n",
    "        out = [\n",
    "            {\"Dataset\": row[\"Dataset\"], \"Group\": row[\"Group\"], \"RelPeaks\": row[\"RelPeaks\"]}\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "    print(f\"Loaded histogram_data from {source} ({len(df)} rows)\")\n",
    "    return out\n",
    "# List-of-dicts (original shape)\n",
    "histogram_data = load_histogram_data()\n",
    "\n",
    "# Or a handy dict mapping for compute functions\n",
    "histogram_dict = load_histogram_data(as_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "786a1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_metrics_record(record):\n",
    "    global metrics_df\n",
    "\n",
    "    # Reload CSV if DataFrame empty\n",
    "    if (metrics_df is None or metrics_df.empty) and csv_path.exists():\n",
    "        metrics_df = pd.read_csv(csv_path)\n",
    "        for col in metrics_df.columns:\n",
    "            if metrics_df[col].dtype == \"object\":\n",
    "                metrics_df[col] = metrics_df[col].apply(safe_json_load)\n",
    "\n",
    "    # Append record\n",
    "    new_df = pd.DataFrame([record])\n",
    "    metrics_df = pd.concat([metrics_df, new_df], ignore_index=True)\n",
    "\n",
    "    # Convert lists to JSON before saving\n",
    "    df_to_save = metrics_df.copy()\n",
    "    for col in [\"peak_times\", \"burst_windows\"]:\n",
    "        if col in df_to_save.columns:\n",
    "            df_to_save[col] = df_to_save[col].apply(lambda x: json.dumps(x) if isinstance(x, (list, tuple)) else x)\n",
    "\n",
    "    df_to_save.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {len(metrics_df)} total records to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ae49d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded burst_features_df from burst_features_full_summary.csv (32 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_burst_features_df(path=\"burst_features_full_summary.csv\"):\n",
    "    \"\"\"\n",
    "    Load burst_features_df from CSV (or Parquet if available).\n",
    "    Returns an empty DataFrame if no file is found.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    parquet_path = path.with_suffix(\".parquet\")\n",
    "\n",
    "    if parquet_path.exists():\n",
    "        try:\n",
    "            df = pd.read_parquet(parquet_path)\n",
    "            print(f\"Loaded burst_features_df from {parquet_path} ({len(df)} rows)\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load Parquet: {e}\")\n",
    "\n",
    "    if path.exists():\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Loaded burst_features_df from {path} ({len(df)} rows)\")\n",
    "        return df\n",
    "\n",
    "    print(f\"No saved burst_features_df found at {path}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Example usage after restart:\n",
    "burst_features_df = load_burst_features_df(\"burst_features_full_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d0ad978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved file found at: burst_features_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Save burst_features_df to CSV ---\n",
    "def save_burst_features(df, path=\"burst_features_combined.csv\"):\n",
    "    if df is not None and not df.empty:\n",
    "        df.to_csv(path, index=False)\n",
    "        print(f\"Saved burst_features_df to {path}\")\n",
    "    else:\n",
    "        print(\"Nothing to save (DataFrame is empty).\")\n",
    "\n",
    "# --- Reload burst_features_df from CSV ---\n",
    "def load_burst_features(path=\"burst_features_combined.csv\"):\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    if Path(path).exists():\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Reloaded burst_features_df from {path}. Shape: {df.shape}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No saved file found at:\", path)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage:\n",
    "# save_burst_features(burst_features_df)\n",
    "burst_features_df = load_burst_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6d496cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset_dict, burst_features_df\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# --- Run the combined function ---\u001b[39;00m\n\u001b[1;32m     49\u001b[0m dataset_dict, burst_features_df \u001b[38;5;241m=\u001b[39m compute_and_save_burst_features(\n\u001b[0;32m---> 50\u001b[0m     orc, \u001b[43mdataset_groups\u001b[49m, config, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mburst_features_combined.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_groups' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_and_save_burst_features(orc, dataset_groups, config, save_path=\"burst_features_combined.csv\"):\n",
    "    \"\"\"\n",
    "    Computes burst features for all datasets, saves them to CSV,\n",
    "    and initializes dataset_dict and burst_features_df for plotting UI.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "    all_results = []\n",
    "\n",
    "    print(\"Computing burst features for all dataset groups...\")\n",
    "\n",
    "    # Loop through each dataset in each group\n",
    "    for group_name, datasets in dataset_groups.items():\n",
    "        for dataset_key in datasets:\n",
    "            try:\n",
    "                # Compute burst features\n",
    "                df = compute_burst_features_full(orc, {dataset_key: [dataset_key]}, config, histogram_data)\n",
    "                \n",
    "                if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "                    df[\"Group\"] = group_name  # add group label\n",
    "                    all_results.append(df)\n",
    "                    dataset_dict[dataset_key] = df\n",
    "                    print(f\"Processed: {dataset_key} ({len(df)} rows)\")\n",
    "                else:\n",
    "                    print(f\"No data returned for {dataset_key}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {dataset_key}: {e}\")\n",
    "\n",
    "    # Combine all results\n",
    "    if all_results:\n",
    "        burst_features_df = pd.concat(all_results, ignore_index=True)\n",
    "        burst_features_df['SampleID'] = burst_features_df['Dataset'].str.split('_').str[0]\n",
    "\n",
    "        # Save to CSV\n",
    "        burst_features_df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nSaved all burst features to {save_path}\")\n",
    "        print(f\"Final dataframe shape: {burst_features_df.shape}\")\n",
    "        print(\"Sample IDs:\", burst_features_df['SampleID'].unique())\n",
    "    else:\n",
    "        burst_features_df = pd.DataFrame()\n",
    "        print(\"No burst features computed.\")\n",
    "\n",
    "    return dataset_dict, burst_features_df\n",
    "\n",
    "# --- Run the combined function ---\n",
    "dataset_dict, burst_features_df = compute_and_save_burst_features(\n",
    "    orc, dataset_groups, config, save_path=\"burst_features_combined.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc48fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate Dataset IDs found in Main DF\n",
      "No duplicate Dataset IDs found in Burst Features DF\n",
      "All SampleIDs have consistent timepoints in Main DF\n",
      "\n",
      "=== Integrity Check Report ===\n",
      "All checks passed. Dataframes appear consistent and ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def integrity_check_dataframes(main_df=None, burst_df=None, histogram_df=None):\n",
    "    \"\"\"\n",
    "    Detects duplicates (Dataset IDs repeated)\n",
    "    Warns if some SampleIDs have fewer timepoints than others (possible missing recordings)\n",
    "    Cross-checks consistency between histogram and burst features dataframes\n",
    "    Flags redundant rows that could skew plots or stats\n",
    "    Produces a clean report (passed / issues found)\n",
    "\n",
    "    Performs integrity checks across multiple dataframes to ensure:\n",
    "    - No duplicate Dataset IDs\n",
    "    - No missing timepoints within each SampleID\n",
    "    - Consistency of SampleIDs across different dataframes\n",
    "    - No redundant rows that could bias plots or stats\n",
    "    \"\"\"\n",
    "\n",
    "    issues = []\n",
    "\n",
    "    # --- Check duplicates within each dataframe ---\n",
    "    for name, df in {\n",
    "        \"Main DF\": main_df,\n",
    "        \"Burst Features DF\": burst_df,\n",
    "        \"Histogram DF\": histogram_df\n",
    "    }.items():\n",
    "        if df is not None:\n",
    "            dupes = df[df.duplicated(subset=[\"Dataset\"])]\n",
    "            if not dupes.empty:\n",
    "                issues.append(f\"{name} contains {len(dupes)} duplicate Dataset entries.\")\n",
    "            else:\n",
    "                print(f\"No duplicate Dataset IDs found in {name}\")\n",
    "\n",
    "    # --- Check for missing timepoints per SampleID ---\n",
    "    if main_df is not None and \"SampleID\" in main_df.columns and \"Timepoint\" in main_df.columns:\n",
    "        timepoint_counts = main_df.groupby(\"SampleID\")[\"Timepoint\"].nunique()\n",
    "        missing_tp = timepoint_counts[timepoint_counts < timepoint_counts.max()]\n",
    "        if not missing_tp.empty:\n",
    "            issues.append(f\"Some SampleIDs have fewer timepoints: {missing_tp.to_dict()}\")\n",
    "        else:\n",
    "            print(\"All SampleIDs have consistent timepoints in Main DF\")\n",
    "\n",
    "    # --- Cross-reference SampleIDs between dataframes ---\n",
    "    if burst_df is not None and histogram_df is not None:\n",
    "        burst_ids = set(burst_df[\"SampleID\"].unique())\n",
    "        hist_ids = set(histogram_df[\"SampleID\"].unique())\n",
    "        missing_in_burst = hist_ids - burst_ids\n",
    "        missing_in_hist = burst_ids - hist_ids\n",
    "        if missing_in_burst:\n",
    "            issues.append(f\" {len(missing_in_burst)} SampleIDs are in Histogram DF but missing in Burst Features DF: {missing_in_burst}\")\n",
    "        if missing_in_hist:\n",
    "            issues.append(f\" {len(missing_in_hist)} SampleIDs are in Burst Features DF but missing in Histogram DF: {missing_in_hist}\")\n",
    "        if not missing_in_burst and not missing_in_hist:\n",
    "            print(\"SampleIDs match between Burst Features and Histogram DF\")\n",
    "\n",
    "    # --- Check redundant rows (Dataset + Timepoint duplicates) ---\n",
    "    for name, df in {\n",
    "        \"Main DF\": main_df,\n",
    "        \"Burst Features DF\": burst_df,\n",
    "        \"Histogram DF\": histogram_df\n",
    "    }.items():\n",
    "        if df is not None and {\"Dataset\", \"Timepoint\"} <= set(df.columns):\n",
    "            redund = df[df.duplicated(subset=[\"Dataset\", \"Timepoint\"])]\n",
    "            if not redund.empty:\n",
    "                issues.append(f\"{name} has redundant rows for the same Dataset/Timepoint combination.\")\n",
    "\n",
    "    print(\"\\n=== Integrity Check Report ===\")\n",
    "    if issues:\n",
    "        for issue in issues:\n",
    "            print(issue)\n",
    "    else:\n",
    "        print(\"All checks passed. Dataframes appear consistent and ready for analysis.\")\n",
    "\n",
    "# example run (replace these with your actual dataframe variables if named differently)\n",
    "integrity_check_dataframes(\n",
    "    main_df=burst_features_df,\n",
    "    burst_df=burst_features_df,\n",
    "    histogram_df=histogram_data if isinstance(histogram_data, pd.DataFrame) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5bc7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics_df to /Users/main_mac/bioinformatics/projects/parkinsons/metrics.csv (519 rows)\n",
      "Saved histogram_data to /Users/main_mac/bioinformatics/projects/parkinsons/histogram_data.csv (32 datasets)\n",
      "Saved burst_features_df to /Users/main_mac/bioinformatics/projects/parkinsons/burst_features_full_summary.csv (32 rows)\n",
      "Session artifacts saved.\n"
     ]
    }
   ],
   "source": [
    "# Ensure SampleID exists on burst_features_df before saving\n",
    "if 'burst_features_df' in globals() and not burst_features_df.empty and 'SampleID' not in burst_features_df.columns:\n",
    "    burst_features_df['SampleID'] = burst_features_df['Dataset'].str.split('_').str[0]\n",
    "\n",
    "# Persist everything we’ve built this session\n",
    "persist_session(\n",
    "    metrics_df=metrics_df,                # from your metrics.csv workflow\n",
    "    histogram_data=histogram_data,        # list of dicts from your histogram plotting step\n",
    "    burst_features_df=burst_features_df,  # the big features table we computed\n",
    "    base_dir=\"~/bioinformatics/projects/parkinsons\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8e85ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metrics_df from /Users/main_mac/bioinformatics/projects/parkinsons/metrics.csv (259 rows)\n",
      "Loaded histogram_data (32 datasets)\n",
      "Loaded burst_features_df from /Users/main_mac/bioinformatics/projects/parkinsons/burst_features_full_summary.csv (32 rows)\n",
      "259 metrics rows\n",
      "32 histogram datasets\n",
      "(32, 23) burst_features_df shape\n"
     ]
    }
   ],
   "source": [
    "# Reload after kernel restart\n",
    "\n",
    "session = reload_session(base_dir=\"~/bioinformatics/projects/parkinsons\")\n",
    "metrics_df = session[\"metrics_df\"]\n",
    "histogram_data_df = session[\"histogram_data_df\"]      # DF version (RelPeaks as JSON strings)\n",
    "histogram_data = session[\"histogram_data_list\"]       # list-of-dicts, RelPeaks as np arrays\n",
    "burst_features_df = session[\"burst_features_df\"]\n",
    "\n",
    "# (Re)add SampleID if needed)\n",
    "if not burst_features_df.empty and 'SampleID' not in burst_features_df.columns:\n",
    "    burst_features_df['SampleID'] = burst_features_df['Dataset'].str.split('_').str[0]\n",
    "\n",
    "# Quick audit\n",
    "print(len(metrics_df), \"metrics rows\")\n",
    "print(len(histogram_data), \"histogram datasets\")\n",
    "print(burst_features_df.shape, \"burst_features_df shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8014dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to dataset: M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr\n",
      "Set 'M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr' as default dataset (first available).\n"
     ]
    }
   ],
   "source": [
    "from projects.parkinsons.coordinator import OrchestratorPDx2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import VBox, HBox, FloatSlider, IntSlider, Dropdown, Button, Output\n",
    "\n",
    "spike_path = Path(\"~/bioinformatics/data/extracted//maxtwo_H9SynGFP\").expanduser()\n",
    "orc = OrchestratorPDx2(spike_path)\n",
    "\n",
    "bin_size_ms_slider = FloatSlider(value=10, min=1, max=20, step=1, description=\"BinSize (ms)\")\n",
    "threshold_slider = FloatSlider(min=1, max=5, step=0.1, value=3.0, description=\"RMSThresh\")\n",
    "edge_slider = FloatSlider(min=0.05, max=0.5, step=0.01, value=0.1, description=\"EdgeThresh\")\n",
    "gauss_slider = IntSlider(min=1, max=200, step=2, value=100, description=\"Gaussian\")\n",
    "square_slider = IntSlider(min=1, max=100, step=2, value=20, description=\"Square\")\n",
    "min_dist_slider = IntSlider(min=100, max=5000, step=50, value=300, description=\"MinDist\")\n",
    "time_start_slider = IntSlider(min=0, max=1800, step=10, value=0, description=\"Start(s)\")\n",
    "window_slider = IntSlider(min=10, max=510, step=5, value=120, description=\"Duration(s)\")\n",
    "\n",
    "dataset_dropdown = Dropdown(options=orc.list_datasets(), value=orc.list_datasets()[2], description='Dataset:')\n",
    "run_button = Button(description=\"Update Plot\", button_style=\"success\")\n",
    "out = Output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6ab344a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d1207fd6e8461ab2bc7b4b57ad2300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Dataset:', index=2, options=('M06943bs1_H9SynGFP_D42_175µM…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_plot(change=None):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        try:\n",
    "            plt.close('all')\n",
    "\n",
    "            dataset = dataset_dropdown.value\n",
    "            time_start = time_start_slider.value\n",
    "            time_window = window_slider.value\n",
    "\n",
    "            config = {\n",
    "                \"bin_size_ms\": bin_size_ms_slider.value,\n",
    "                \"threshold_rms\": threshold_slider.value,\n",
    "                \"burst_edge_fraction\": edge_slider.value,\n",
    "                \"gauss_win_ms\": gauss_slider.value,\n",
    "                \"square_win_ms\": square_slider.value,\n",
    "                \"min_dist_ms\": min_dist_slider.value,\n",
    "                \"time_start\": time_start,\n",
    "                \"time_window\": time_window\n",
    "            }\n",
    "\n",
    "            time_range = (time_start, time_start + time_window)\n",
    "\n",
    "            print(f\"Selected dataset: {dataset}\")\n",
    "            print(f\"Time range: {time_range}\")\n",
    "            print(f\"Config: {config}\")\n",
    "\n",
    "            # Run orchestrator\n",
    "            orc.compute_and_plot_population_bursts(\n",
    "                dataset_keys=[dataset],\n",
    "                config=config,\n",
    "                time_range=time_range,\n",
    "                save=False\n",
    "            )\n",
    "\n",
    "            latest_df = orc.burst_detection_metrics_df\n",
    "            if latest_df.empty:\n",
    "                print(\"No metrics generated.\")\n",
    "                return\n",
    "\n",
    "            # === Take the full transient row ===\n",
    "            latest = latest_df[latest_df[\"Sample\"] == dataset].iloc[-1].to_dict()\n",
    "\n",
    "            if latest.get(\"duration_s\", 0) == 0:\n",
    "                print(\"No spikes in selected time window. Try another dataset.\")\n",
    "                return\n",
    "\n",
    "            # Print key burst summary\n",
    "            print(f\"\\nBurst Extraction Summary — {dataset}\")\n",
    "            print(f\"Recording duration: {latest['duration_s']:.2f} s\")\n",
    "            print(f\"Total spikes: {latest['n_total_spikes']}\")\n",
    "            print(f\"Number of neurons: {latest['n_neurons']}\")\n",
    "            print(f\"Mean firing rate per neuron: {latest['mean_rate_per_neuron']:.2f} Hz\")\n",
    "            if latest[\"n_total_bursts\"] > 0:\n",
    "                print(f\"Bursts detected: {latest['n_total_bursts']}\")\n",
    "                print(f\"Mean burst duration: {latest['mean_burst_dur']:.3f} s\")\n",
    "                print(f\"Std of burst durations: {latest['std_burst_dur']:.3f} s\")\n",
    "                print(f\"Burst rate: {latest['burst_rate_per_min']:.2f} bursts/min\")\n",
    "                if latest[\"mean_IBI\"]:\n",
    "                    print(f\"Mean inter-burst interval (IBI): {latest['mean_IBI']:.2f} s\")\n",
    "\n",
    "            # Merge transient metrics and config\n",
    "            record = {**latest, **config, \"Sample\": dataset}\n",
    "\n",
    "            # Find match\n",
    "            global metrics_df\n",
    "            match_idx = None\n",
    "            for idx, existing in metrics_df.iterrows():\n",
    "                if all(existing.get(k) == record[k] for k in [\"Sample\", \"bin_size_ms\", \"threshold_rms\", \n",
    "                                                               \"burst_edge_fraction\", \"gauss_win_ms\", \n",
    "                                                               \"square_win_ms\", \"min_dist_ms\", \n",
    "                                                               \"time_start\", \"time_window\"]):\n",
    "                    match_idx = idx\n",
    "                    break\n",
    "\n",
    "            if match_idx is not None:\n",
    "                metrics_df.loc[match_idx] = record\n",
    "                print(\"Updated existing record.\")\n",
    "            else:\n",
    "                append_metrics_record(record)\n",
    "                print(\"Added new record.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            print(f\"Error during update_plot: {e}\")\n",
    "\n",
    "# Hook up the run button\n",
    "run_button.on_click(update_plot)\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([dataset_dropdown, run_button]),\n",
    "    HBox([bin_size_ms_slider, threshold_slider, edge_slider]),\n",
    "    HBox([gauss_slider, square_slider, min_dist_slider]),\n",
    "    HBox([time_start_slider, window_slider]),\n",
    "    out\n",
    "])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = {\n",
    "    \"bin_size_ms\": 9.0,\n",
    "    \"threshold_rms\": 1.7,\n",
    "    \"burst_edge_fraction\": 0.1,\n",
    "    \"gauss_win_ms\": 85.0,\n",
    "    \"square_win_ms\": 19.0,\n",
    "    \"min_dist\": 1200.0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_groups = {\n",
    "    \"Control\": [\n",
    "        \n",
    "        \"M08754bs1_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs1_H9SynGFP_D43_CONTROL_T1_3hr\",\n",
    "        \"M08754bs1_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs1_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs1_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs1_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs1_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs1_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs1_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs1_H9SynGFP_D49_CONTROL_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M08754bs2_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs2_H9SynGFP_D42_CONTROL_T1_3hr\",\n",
    "        \"M08754bs2_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs2_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs2_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs2_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs2_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs2_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs2_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs2_H9SynGFP_D49_CONTROL_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M08754bs3_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs3_H9SynGFP_D42_CONTROL_T1_3hr\",\n",
    "        \"M08754bs3_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs3_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs3_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs3_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs3_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs3_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs3_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs3_H9SynGFP_D49_CONTROL_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M08754bs4_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs4_H9SynGFP_D42_CONTROL_T1_3hr\",\n",
    "        \"M08754bs4_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs4_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs4_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs4_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs4_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs4_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs4_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs4_H9SynGFP_D49_CONTROL_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M08754bs5_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs5_H9SynGFP_D42_CONTROL_T1_3hr\",\n",
    "        \"M08754bs5_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs5_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs5_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs5_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs5_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs5_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs5_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs5_H9SynGFP_D49_CONTROL_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M08754bs6_H9SynGFP_D42_CONTROL_BASELINE_0hr\",\n",
    "        \"M08754bs6_H9SynGFP_D42_CONTROL_T1_3hr\",\n",
    "        \"M08754bs6_H9SynGFP_D43_CONTROL_T1_24hr\",\n",
    "        \"M08754bs6_H9SynGFP_D43_CONTROL_T2_3hr\",\n",
    "        \"M08754bs6_H9SynGFP_D44_CONTROL_T2_24hr\",\n",
    "        \"M08754bs6_H9SynGFP_D45_CONTROL_T2_48hr\",\n",
    "        \"M08754bs6_H9SynGFP_D46_CONTROL_T2_72hr\",\n",
    "        \"M08754bs6_H9SynGFP_D47_CONTROL_T2_D4\",\n",
    "        \"M08754bs6_H9SynGFP_D48_CONTROL_T2_D5\",\n",
    "        \"M08754bs6_H9SynGFP_D49_CONTROL_T2_D6\"\n",
    "    ],\n",
    "\n",
    "    \"Treated\": [\n",
    "        \n",
    "        \"M06943bs1_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs1_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs1_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs1_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs1_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs1_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs1_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs1_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs1_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs1_H9SynGFP_D49_175µM_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M06943bs2_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs2_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs2_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs2_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs2_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs2_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs2_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs2_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs2_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs2_H9SynGFP_D49_175µM_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M06943bs3_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs3_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs3_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs3_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs3_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs3_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs3_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs3_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs3_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs3_H9SynGFP_D49_175µM_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M06943bs4_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs4_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs4_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs4_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs4_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs4_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs4_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs4_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs4_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs4_H9SynGFP_D49_175µM_T2_D6\",\n",
    "\n",
    "        \n",
    "        \"M06943bs5_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs5_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs5_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs5_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs5_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs5_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs5_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs5_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs5_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs5_H9SynGFP_D49_175µM_T2_D6\",\n",
    "\n",
    "       \n",
    "        \"M06943bs6_H9SynGFP_D42_175µM_BASELINE_0hr\",\n",
    "        \"M06943bs6_H9SynGFP_D42_175µM_T1_3hr\",\n",
    "        \"M06943bs6_H9SynGFP_D43_175µM_T1_24hr\",\n",
    "        \"M06943bs6_H9SynGFP_D43_175µM_T2_3hr\",\n",
    "        \"M06943bs6_H9SynGFP_D44_175µM_T2_24hr\",\n",
    "        \"M06943bs6_H9SynGFP_D45_175µM_T2_48hr\",\n",
    "        \"M06943bs6_H9SynGFP_D46_175µM_T2_72hr\",\n",
    "        \"M06943bs6_H9SynGFP_D47_175µM_T2_D4\",\n",
    "        \"M06943bs6_H9SynGFP_D48_175µM_T2_D5\",\n",
    "        \"M06943bs6_H9SynGFP_D49_175µM_T2_D6\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute & save burst features ---\n",
    "dataset_dict, burst_features_df = compute_and_save_burst_features(\n",
    "    orc, dataset_groups, config, histogram_data, save_path=\"burst_features_combined.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d063b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07423e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_histogram_entry(entry, base_dir=\"~/bioinformatics/projects/parkinsons\"):\n",
    "    \"\"\"\n",
    "    Upsert a single histogram entry (replace same Dataset if exists)\n",
    "    \"\"\"\n",
    "    base = Path(base_dir).expanduser()\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = base / \"histogram_data.csv\"\n",
    "    pq_path = base / \"histogram_data.parquet\"\n",
    "\n",
    "    if csv_path.exists():\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[\"Dataset\", \"Group\", \"RelPeaks\", \"N\", \"Min\", \"Max\"])\n",
    "\n",
    "    rel = entry.get(\"RelPeaks\", [])\n",
    "    if isinstance(rel, np.ndarray):\n",
    "        rel = rel.tolist()\n",
    "\n",
    "    new_row = {\n",
    "        \"Dataset\": entry.get(\"Dataset\"),\n",
    "        \"Group\": entry.get(\"Group\"),\n",
    "        \"RelPeaks\": json.dumps(rel),\n",
    "        \"N\": len(rel),\n",
    "        \"Min\": (min(rel) if len(rel) else None),\n",
    "        \"Max\": (max(rel) if len(rel) else None),\n",
    "    }\n",
    "\n",
    "    df = df[df[\"Dataset\"] != new_row[\"Dataset\"]]\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    try:\n",
    "        df.to_parquet(pq_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Parquet save skipped: {e}\")\n",
    "\n",
    "    print(f\"Saved histogram_data entry for {new_row['Dataset']} ({len(df)} total datasets)\")\n",
    "    return csv_path, pq_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
